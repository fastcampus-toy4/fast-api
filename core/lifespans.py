from contextlib import asynccontextmanager
from fastapi import FastAPI
from langchain_openai import ChatOpenAI

# services í´ë”ì˜ data_loaderë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •í•©ë‹ˆë‹¤.
from services import data_loader
from core.config import settings

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë¼ì´í”„ì‚¬ì´í´(ì‹œì‘/ì¢…ë£Œ)ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
    ì„œë²„ ì‹œì‘ ì‹œ AI ëª¨ë¸ê³¼ í•„ìš”í•œ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ì˜¬ë¦½ë‹ˆë‹¤.
    """
    print("="*50)
    print("AI ë§›ì§‘ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    # --- 1. AI ëª¨ë¸(LLM) ì´ˆê¸°í™” ---
    # app.stateì— llm ê°ì²´ë¥¼ ë§Œë“¤ì–´ ë‹¤ë¥¸ íŒŒì¼ì—ì„œ ê³µìœ í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    app.state.llm = ChatOpenAI(model="gpt-4o", temperature=0, api_key=settings.OPENAI_API_KEY)
    print("âœ… AI ëª¨ë¸(LLM)ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- 2. ì‚¬ì „ ë°ì´í„° ë¡œë“œ ---
    try:
        data_loader.load_all_data()
        print("âœ… ì‚¬ì „ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë©”ëª¨ë¦¬ì— ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ğŸ”¥ [ì˜¤ë¥˜] ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: ë°ì´í„° ë¡œë”© ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print(f"    - ì˜¤ë¥˜ ë‚´ìš©: {e}")
        import traceback
        traceback.print_exc()

    print("="*50)
    print("ğŸš€ ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    yield
    
    # --- ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë  ì½”ë“œ ---
    print("ğŸ‘‹ ì‹œìŠ¤í…œì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")